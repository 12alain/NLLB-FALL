{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"dd463cf89b4f4120a4a2b63f27767282":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fa8dab21bb54930925528faff61064a","IPY_MODEL_2d30536cd4084fb4aef11f0208137f58","IPY_MODEL_6d7cd32fd780405eb09f452bb80b20c6"],"layout":"IPY_MODEL_fe125af781924a07ba0adee288d77f0c"}},"8fa8dab21bb54930925528faff61064a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7449499d049d439c9400e52e52c96a91","placeholder":"​","style":"IPY_MODEL_fdd1d535a75c4b5bb54be294b7e5d638","value":"Map: 100%"}},"2d30536cd4084fb4aef11f0208137f58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13ce6cf3b9174564bf245940c2bd7525","max":21401,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98a4f5d728b9492d93b3cc80435543ad","value":21401}},"6d7cd32fd780405eb09f452bb80b20c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3967d1eaf3964ed29a8e7ded4c093964","placeholder":"​","style":"IPY_MODEL_18401a5fb70c496cafc4a2180ceb2677","value":" 21401/21401 [00:54&lt;00:00, 510.63 examples/s]"}},"fe125af781924a07ba0adee288d77f0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7449499d049d439c9400e52e52c96a91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd1d535a75c4b5bb54be294b7e5d638":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13ce6cf3b9174564bf245940c2bd7525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98a4f5d728b9492d93b3cc80435543ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3967d1eaf3964ed29a8e7ded4c093964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18401a5fb70c496cafc4a2180ceb2677":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64f1d9d72d5d44a996ce9bbd8b01cc1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61def207bf314cc08fcce27f03bca6e7","IPY_MODEL_76afa0c084b2492d80ff9c42a0145734","IPY_MODEL_5d753abf39fa4d03be96bcf015a9a9ed"],"layout":"IPY_MODEL_3d6d07e5b2844e318d16fdd26570c8d0"}},"61def207bf314cc08fcce27f03bca6e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4790bfe1d2004a94aad933b97f2a8f39","placeholder":"​","style":"IPY_MODEL_b984fd249eb24c0e9afe5c8c17a5a94d","value":"Map: 100%"}},"76afa0c084b2492d80ff9c42a0145734":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c36b87b8d2024920a0d52a56e1d0ebda","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64d604f0af4b4013b06cdcd208bffd2e","value":1500}},"5d753abf39fa4d03be96bcf015a9a9ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6851f84f3aa14b329de9b07f55e3c2bd","placeholder":"​","style":"IPY_MODEL_7a4906e2626843d5903ff39ce495d9fd","value":" 1500/1500 [00:02&lt;00:00, 631.82 examples/s]"}},"3d6d07e5b2844e318d16fdd26570c8d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4790bfe1d2004a94aad933b97f2a8f39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b984fd249eb24c0e9afe5c8c17a5a94d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c36b87b8d2024920a0d52a56e1d0ebda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d604f0af4b4013b06cdcd208bffd2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6851f84f3aa14b329de9b07f55e3c2bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4906e2626843d5903ff39ce495d9fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf44ae3c1e6f42919706bf0a391d66d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab6043f555f543048367c47f57485c16","IPY_MODEL_597e0dab1f154a5a8b24877199a2dfd1","IPY_MODEL_13dff4d84fea455e982fd953be8d58b2"],"layout":"IPY_MODEL_724a67b202074cb0a6941afcff22c5b2"}},"ab6043f555f543048367c47f57485c16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea78c63fdea64bc58473bbec70a847d0","placeholder":"​","style":"IPY_MODEL_c95c077c199b4dc7932a8b1718e60535","value":"Map: 100%"}},"597e0dab1f154a5a8b24877199a2dfd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcf498f235c64a1abeee1bb0eef351da","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f8171a7e5634fb7b41d004dea025b50","value":1500}},"13dff4d84fea455e982fd953be8d58b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abb92a4afcda48f799439f39e266e8e4","placeholder":"​","style":"IPY_MODEL_27bd2d17a114428281b48035d32764ff","value":" 1500/1500 [00:02&lt;00:00, 662.70 examples/s]"}},"724a67b202074cb0a6941afcff22c5b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea78c63fdea64bc58473bbec70a847d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95c077c199b4dc7932a8b1718e60535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcf498f235c64a1abeee1bb0eef351da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8171a7e5634fb7b41d004dea025b50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abb92a4afcda48f799439f39e266e8e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27bd2d17a114428281b48035d32764ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TP : Fine-tuning de GPT-2 pour le résumé de texte en français\n\n## Objectif\nL'objectif de ce TP Est de s'inspirer de l'article [Sculpting Language: GPT-2 Fine-Tuning with LoRa](https://blog.devgenius.io/sculpting-language-gpt-2-fine-tuning-with-lora-1caf3bfbc3c6) pour effectuer le fine-tuning du modèle GPT-2 afin de réaliser des résumés de textes en français.\n\n## Étapes\n\n1. **Préparation du modèle**\n   - Trouver un checkpoint GPT-2 pré-entraîné en français sur huggingFace.\n\n2. **Préparation des données**\n   - Identifier et obtenir un corpus de résumés de textes en français sur huggingFace.\n   - Charger le corpus dans l'environnement de travail.\n   - Visualiser et analyser le corpus pour s'assurer de sa qualité et de sa pertinence.\n\n3. **Fine-tuning avec LoRA**\n   - Préparer l'environnement pour utiliser LoRA (Low-Rank Adaptation).\n   - Configurer les hyperparamètres pour LoRA.\n   - Effectuer le fine-tuning du modèle GPT-2 avec LoRA sur le corpus de résumés.\n   - Évaluer les performances du modèle fine-tuné.\n\n4. **Fine-tuning avec QLoRA**\n   - Préparer l'environnement pour utiliser QLoRA (Quantized LoRA).\n   - Configurer les hyperparamètres pour QLoRA.\n   - Effectuer le fine-tuning du modèle GPT-2 avec QLoRA sur le même corpus.\n   - Comparer les performances et l'efficacité entre LoRA et QLoRA.\n\n5. **Évaluation et comparaison**\n   - Tester les modèles fine-tunés sur des textes non vus.\n   - Analyser la qualité des résumés produits.\n   - Comparer les résultats obtenus avec LoRA et QLoRA.\n\n6. **Conclusion**\n  - Faire un conclusion","metadata":{"id":"1DQGYUhXqTVX"}},{"cell_type":"markdown","source":"#Préparation du modèle\n\nTrouver un checkpoint GPT-2 pré-entraîné en français sur huggingFace.\n","metadata":{"id":"JDUVWsuPVswk"}},{"cell_type":"code","source":"!pip install peft\n!pip install transformers\n!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F80Flj8wl6Le","outputId":"c2c2e7d2-a1ca-42e9-d902-4d97251ae8dc","execution":{"iopub.status.busy":"2024-10-07T10:31:38.180498Z","iopub.execute_input":"2024-10-07T10:31:38.181601Z","iopub.status.idle":"2024-10-07T10:32:13.401426Z","shell.execute_reply.started":"2024-10-07T10:31:38.181543Z","shell.execute_reply":"2024-10-07T10:32:13.400140Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import LoraConfig, get_peft_model\nfrom datasets import load_dataset\n\n# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"asi/gpt-fr-cased-base\",\n    device_map='auto',\n)\n\n","metadata":{"id":"bvf0lfcoVxxJ","execution":{"iopub.status.busy":"2024-10-07T10:32:13.403775Z","iopub.execute_input":"2024-10-07T10:32:13.404134Z","iopub.status.idle":"2024-10-07T10:32:15.860756Z","shell.execute_reply.started":"2024-10-07T10:32:13.404098Z","shell.execute_reply":"2024-10-07T10:32:15.859722Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"asi/gpt-fr-cased-base\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"0eRbaZ9dA_qh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbd2c2b5-c208-4a78-e91f-f261e54ab945","execution":{"iopub.status.busy":"2024-10-07T10:32:15.862065Z","iopub.execute_input":"2024-10-07T10:32:15.862475Z","iopub.status.idle":"2024-10-07T10:32:16.363192Z","shell.execute_reply.started":"2024-10-07T10:32:15.862430Z","shell.execute_reply":"2024-10-07T10:32:16.362198Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Préparation des données\n\nIdentifier et obtenir un corpus de résumés de textes en français sur huggingFace.\nCharger le corpus dans l'environnement de travail.\nVisualiser et analyser le corpus pour s'assurer de sa qualité et de sa pertinence.","metadata":{"id":"zJB0DaeAV8V2"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GrCqmVLEQif","outputId":"31af0e20-d83e-4350-9fde-03d7b5bddbe7","execution":{"iopub.status.busy":"2024-10-07T10:32:16.364455Z","iopub.execute_input":"2024-10-07T10:32:16.364770Z","iopub.status.idle":"2024-10-07T10:32:28.499204Z","shell.execute_reply.started":"2024-10-07T10:32:16.364737Z","shell.execute_reply":"2024-10-07T10:32:28.498062Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# LOAD AND STURCTURE DATA\nfrom datasets import load_dataset\ndata = load_dataset(\"EdinburghNLP/orange_sum\",\"abstract\")","metadata":{"id":"lxLVRXM-0X8U","execution":{"iopub.status.busy":"2024-10-07T10:32:28.503277Z","iopub.execute_input":"2024-10-07T10:32:28.504275Z","iopub.status.idle":"2024-10-07T10:32:29.432536Z","shell.execute_reply.started":"2024-10-07T10:32:28.504222Z","shell.execute_reply":"2024-10-07T10:32:29.431548Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# affichage du dataset\ndata","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHq0SylzWoQA","outputId":"a5c4c10c-1c54-4e91-fc16-8a1669c4b302","execution":{"iopub.status.busy":"2024-10-07T10:32:29.433863Z","iopub.execute_input":"2024-10-07T10:32:29.434586Z","iopub.status.idle":"2024-10-07T10:32:29.440977Z","shell.execute_reply.started":"2024-10-07T10:32:29.434539Z","shell.execute_reply":"2024-10-07T10:32:29.439807Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 21401\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 1500\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 1500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data['train'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K56rlRFWdjDi","outputId":"6f91c943-e049-430d-8510-b10e597fae29","execution":{"iopub.status.busy":"2024-10-07T10:32:29.442412Z","iopub.execute_input":"2024-10-07T10:32:29.442796Z","iopub.status.idle":"2024-10-07T10:32:29.452788Z","shell.execute_reply.started":"2024-10-07T10:32:29.442730Z","shell.execute_reply":"2024-10-07T10:32:29.451884Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'text': 'Thierry Mariani sur la liste du Rassemblement national (RN, ex-FN) aux européennes ? C\\'est ce qu\\'affirme mardi 11 septembre Chez Pol, la nouvelle newsletter politique de Libération. L\\'ancien député Les Républicain et ministre de Nicolas Sarkozy serait sur le point de rejoindre les troupes de Marine Le Pen pour le élections européennes de 2019. \"Ça va se faire. Ce n\\'est plus qu\\'une question de calendrier. On n\\'est pas obligé de l\\'annoncer tout de suite, à huit mois des européennes\", aurait ainsi assuré un membre influent du RN. Contacté par Franceinfo, M. Mariani n\\'a pas confirmé l\\'information. \"Les élections sont en juin, je ne sais même pas qui sera numéro 1 sur la liste\", a répondu l\\'ancien ministre des Transports. Il reconnaît toutefois, toujours cité par Franceinfo, que son nom sur la liste du RN \"fait partie des possibilités\". \"Fréjus est une ville sympathique mais je n\\'ai pas prévu de m\\'y rendre ce week_end\", a-t-il par ailleurs commenté sur Twitter alors que Marine Le Pen réunit les cadres de son parti ce week-end dans la cité varoise. Une proximité connue avec le FNLa proximité de Thierry Mariani avec le parti frontiste n\\'est pas nouvelle. \"Sans alliés, nous allons rester dans l\\'opposition pour longtemps. Il est temps de renverser la table. Le Front national a évolué. Regardons si un accord ou un rapprochement sont possibles\", avait-il déclaré dans une interview donnée au Journal du Dimanche en mars dernier. Puis, en avril, avait bruissé la rumeur d\\'un rencontre entre l\\'ex-député et Marine Le Pen, qui lui aurait proposé de figurer en position éligible sur la liste de son parti aux européennes. \"Pas de conclusion hâtive\", avait-il à l\\'époque écrit sur Twitter. Le même mois, Thierry Mariani avait cosigné une tribune publiée dans Valeurs actuelles aux côté d\\'élus frontistes appelant à une union des droites.\\n',\n 'summary': \"L'information n'a pas été confirmée par l'intéressé qui déclare toutefois étudier la question.\\n\"}"},"metadata":{}}]},{"cell_type":"code","source":"data['train'].to_pandas().head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"utUjstwtSRsy","outputId":"a73735c6-a36d-4b5e-a4a8-5fb1175b3988","execution":{"iopub.status.busy":"2024-10-07T10:32:29.453897Z","iopub.execute_input":"2024-10-07T10:32:29.454203Z","iopub.status.idle":"2024-10-07T10:32:29.609756Z","shell.execute_reply.started":"2024-10-07T10:32:29.454171Z","shell.execute_reply":"2024-10-07T10:32:29.608776Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Thierry Mariani sur la liste du Rassemblement ...   \n1  C'est désormais officiel : Alain Juppé n'est p...   \n2  La mesure est décriée par les avocats et les m...   \n3  Dans une interview accordée au Figaro mercredi...   \n4  Le préjudice est estimé à 2 millions d'euros. ...   \n\n                                             summary  \n0  L'information n'a pas été confirmée par l'inté...  \n1  Le maire de Bordeaux ne fait plus partie des R...  \n2  En 2020, les tribunaux d'instance fusionnent a...  \n3  Les médecins jugés \"gros prescripteurs d'arrêt...  \n4  Il aura fallu mobiliser 90 gendarmes pour cett...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thierry Mariani sur la liste du Rassemblement ...</td>\n      <td>L'information n'a pas été confirmée par l'inté...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C'est désormais officiel : Alain Juppé n'est p...</td>\n      <td>Le maire de Bordeaux ne fait plus partie des R...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>La mesure est décriée par les avocats et les m...</td>\n      <td>En 2020, les tribunaux d'instance fusionnent a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dans une interview accordée au Figaro mercredi...</td>\n      <td>Les médecins jugés \"gros prescripteurs d'arrêt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Le préjudice est estimé à 2 millions d'euros. ...</td>\n      <td>Il aura fallu mobiliser 90 gendarmes pour cett...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Appliquer le tokenizer sur le texte original et le résumé\ndef preprocess_function(samples):\n    # Tokenizer le texte d'entrée (text) avec troncation et padding à max_length\n    inputs = tokenizer(\n        samples['text'],\n        truncation=True,\n        padding='max_length',\n        max_length=512\n    )\n    targets = tokenizer(\n        samples['summary'],\n        truncation=True,\n        padding='max_length',\n        max_length=128\n    )\n\n    # Préparer les inputs et les labels\n    inputs['labels'] = targets['input_ids']\n\n    # Remplacer les tokens de padding des labels par -100 pour les ignorer dans la perte\n    inputs['labels'] = [\n        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n        for label in inputs['labels']\n    ]\n\n    return inputs\n\n# Appliquer le tokenizer sur tout le dataset\ndata = data.map(preprocess_function, batched=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["dd463cf89b4f4120a4a2b63f27767282","8fa8dab21bb54930925528faff61064a","2d30536cd4084fb4aef11f0208137f58","6d7cd32fd780405eb09f452bb80b20c6","fe125af781924a07ba0adee288d77f0c","7449499d049d439c9400e52e52c96a91","fdd1d535a75c4b5bb54be294b7e5d638","13ce6cf3b9174564bf245940c2bd7525","98a4f5d728b9492d93b3cc80435543ad","3967d1eaf3964ed29a8e7ded4c093964","18401a5fb70c496cafc4a2180ceb2677","64f1d9d72d5d44a996ce9bbd8b01cc1d","61def207bf314cc08fcce27f03bca6e7","76afa0c084b2492d80ff9c42a0145734","5d753abf39fa4d03be96bcf015a9a9ed","3d6d07e5b2844e318d16fdd26570c8d0","4790bfe1d2004a94aad933b97f2a8f39","b984fd249eb24c0e9afe5c8c17a5a94d","c36b87b8d2024920a0d52a56e1d0ebda","64d604f0af4b4013b06cdcd208bffd2e","6851f84f3aa14b329de9b07f55e3c2bd","7a4906e2626843d5903ff39ce495d9fd","bf44ae3c1e6f42919706bf0a391d66d5","ab6043f555f543048367c47f57485c16","597e0dab1f154a5a8b24877199a2dfd1","13dff4d84fea455e982fd953be8d58b2","724a67b202074cb0a6941afcff22c5b2","ea78c63fdea64bc58473bbec70a847d0","c95c077c199b4dc7932a8b1718e60535","fcf498f235c64a1abeee1bb0eef351da","0f8171a7e5634fb7b41d004dea025b50","abb92a4afcda48f799439f39e266e8e4","27bd2d17a114428281b48035d32764ff"]},"id":"UXsjdz1SSajb","outputId":"83a93e23-2256-4660-f520-ed3706c4209f","execution":{"iopub.status.busy":"2024-10-07T10:32:29.611090Z","iopub.execute_input":"2024-10-07T10:32:29.611539Z","iopub.status.idle":"2024-10-07T10:32:29.731716Z","shell.execute_reply.started":"2024-10-07T10:32:29.611492Z","shell.execute_reply":"2024-10-07T10:32:29.730734Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# 3-Fine-tuning avec LoRA\n\nPréparer l'environnement pour utiliser LoRA (Low-Rank Adaptation).\nConfigurer les hyperparamètres pour LoRA.\nEffectuer le fine-tuning du modèle GPT-2 avec LoRA sur le corpus de résumés.\nÉvaluer les performances du modèle fine-tuné.","metadata":{"id":"GLcZv00p_P5W"}},{"cell_type":"code","source":"# FREEZE WEIGHTS\nfor param in model.parameters():\n    param.requires_grad = False\n\n# LoRa\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.06,\n    bias=\"none\",\n    target_modules=[\"c_attn\", \"c_proj\"],\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, config)","metadata":{"id":"9ctt3cmH_WTa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f33b9ca2-e8f6-4895-83a5-a9c0b6d9e923","execution":{"iopub.status.busy":"2024-10-07T10:32:29.732827Z","iopub.execute_input":"2024-10-07T10:32:29.733130Z","iopub.status.idle":"2024-10-07T10:32:29.942838Z","shell.execute_reply.started":"2024-10-07T10:32:29.733098Z","shell.execute_reply":"2024-10-07T10:32:29.941767Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\n\nprint_trainable_parameters(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6HelORNeYgL8","outputId":"f090f3ae-a37c-472f-886f-9959c0979c6e","execution":{"iopub.status.busy":"2024-10-07T10:32:29.944230Z","iopub.execute_input":"2024-10-07T10:32:29.944583Z","iopub.status.idle":"2024-10-07T10:32:29.955895Z","shell.execute_reply.started":"2024-10-07T10:32:29.944548Z","shell.execute_reply":"2024-10-07T10:32:29.954911Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"trainable params: 7569408 || all params: 1024411136 || trainable%: 0.7389033303128794\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importer les modules nécessaires\nfrom transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback\ndef training(model):\n\n    trainer = Trainer(\n        model=model,\n        train_dataset=data['train'],\n        eval_dataset=data['test'],\n        args=TrainingArguments(\n            per_device_train_batch_size=4,\n            per_device_eval_batch_size=4,\n            gradient_accumulation_steps=2,\n            warmup_steps=100,\n            num_train_epochs=2,\n            learning_rate=7e-5,\n            logging_steps=100,\n            save_steps=100,\n            output_dir='output',\n            weight_decay=0.01,\n            auto_find_batch_size=True,\n            evaluation_strategy=\"steps\",\n            save_strategy=\"steps\",\n            load_best_model_at_end=True,\n            save_total_limit=3,\n        ),\n         # Use the tokenizer's pad method directly in the data collator\n        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n    )\n\n    # Désactiver le cache pour optimiser l'utilisation de la mémoire\n    model.config.use_cache = False\n\n    # Lancer l'entraînement\n    trainer.train()\n","metadata":{"id":"-AHMQacFYj78","execution":{"iopub.status.busy":"2024-10-07T10:32:29.957174Z","iopub.execute_input":"2024-10-07T10:32:29.957609Z","iopub.status.idle":"2024-10-07T10:32:29.967590Z","shell.execute_reply.started":"2024-10-07T10:32:29.957563Z","shell.execute_reply":"2024-10-07T10:32:29.966692Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Training avec LOra\n#training(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"TSbvqJqjSRsz","outputId":"a523db13-f3d8-4204-dbdd-0ec3aef411cc","execution":{"iopub.status.busy":"2024-10-07T10:32:29.968678Z","iopub.execute_input":"2024-10-07T10:32:29.968983Z","iopub.status.idle":"2024-10-07T10:32:29.978478Z","shell.execute_reply.started":"2024-10-07T10:32:29.968950Z","shell.execute_reply":"2024-10-07T10:32:29.977614Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/outputs/checkpoint-5350","metadata":{"execution":{"iopub.status.busy":"2024-10-07T10:32:29.982994Z","iopub.execute_input":"2024-10-07T10:32:29.983266Z","iopub.status.idle":"2024-10-07T10:32:29.992618Z","shell.execute_reply.started":"2024-10-07T10:32:29.983237Z","shell.execute_reply":"2024-10-07T10:32:29.991633Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"/kaggle/working/outputs/checkpoint-5350\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-10-07T10:32:29.993611Z","iopub.execute_input":"2024-10-07T10:32:29.993907Z","iopub.status.idle":"2024-10-07T10:32:31.063259Z","shell.execute_reply.started":"2024-10-07T10:32:29.993874Z","shell.execute_reply":"2024-10-07T10:32:31.062085Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"README.md                  model_5300.zip  \u001b[0m\u001b[01;34moutputs\u001b[0m/       trainer_state.json\nadapter_config.json        model_5350.zip  rng_state.pth  training_args.bin\nadapter_model.safetensors  optimizer.pt    scheduler.pt   \u001b[01;34mwandb\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r model_5300.zip /kaggle/working/outputs/checkpoint-5300","metadata":{"execution":{"iopub.status.busy":"2024-10-07T10:32:31.065047Z","iopub.execute_input":"2024-10-07T10:32:31.065517Z","iopub.status.idle":"2024-10-07T10:32:36.948633Z","shell.execute_reply.started":"2024-10-07T10:32:31.065468Z","shell.execute_reply":"2024-10-07T10:32:36.947544Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"updating: kaggle/working/outputs/checkpoint-5300/ (stored 0%)\nupdating: kaggle/working/outputs/checkpoint-5300/trainer_state.json (deflated 84%)\nupdating: kaggle/working/outputs/checkpoint-5300/README.md (deflated 66%)\nupdating: kaggle/working/outputs/checkpoint-5300/adapter_model.safetensors (deflated 7%)\nupdating: kaggle/working/outputs/checkpoint-5300/scheduler.pt (deflated 55%)\nupdating: kaggle/working/outputs/checkpoint-5300/rng_state.pth (deflated 25%)\nupdating: kaggle/working/outputs/checkpoint-5300/training_args.bin (deflated 51%)\nupdating: kaggle/working/outputs/checkpoint-5300/optimizer.pt (deflated 9%)\nupdating: kaggle/working/outputs/checkpoint-5300/adapter_config.json (deflated 52%)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Enregistrer le modèle après l'entraînement\n#from transformers import Trainer\n#traine.save_model(\"model_best\")","metadata":{"execution":{"iopub.status.busy":"2024-10-07T10:32:36.950184Z","iopub.execute_input":"2024-10-07T10:32:36.950544Z","iopub.status.idle":"2024-10-07T10:32:36.955040Z","shell.execute_reply.started":"2024-10-07T10:32:36.950508Z","shell.execute_reply":"2024-10-07T10:32:36.954092Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Évaluer le modèle sur le jeu de données de validation \n#results = trainer.evaluate(eval_dataset=data['validation'])\n\n# Afficher les résultats\n#print(\"Résultats de l'évaluation :\", results)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T10:32:36.956285Z","iopub.execute_input":"2024-10-07T10:32:36.956614Z","iopub.status.idle":"2024-10-07T10:32:36.966691Z","shell.execute_reply.started":"2024-10-07T10:32:36.956580Z","shell.execute_reply":"2024-10-07T10:32:36.965655Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"BujvYJ3DSRs0"}},{"cell_type":"markdown","source":"# 4- Fine tuning avec Qlora","metadata":{"id":"iYHslPTTSRs0"}},{"cell_type":"markdown","source":"   - Préparer l'environnement pour utiliser QLoRA (Quantized LoRA).\n   - Configurer les hyperparamètres pour QLoRA.\n   - Effectuer le fine-tuning du modèle GPT-2 avec QLoRA sur le même corpus.\n   - Comparer les performances et l'efficacité entre LoRA et QLoRA.","metadata":{"id":"1Qr0odqpSRs0"}},{"cell_type":"code","source":"!pip install bitsandbytes\n","metadata":{"id":"msVqTLyQSRs0","execution":{"iopub.status.busy":"2024-10-07T10:32:36.968121Z","iopub.execute_input":"2024-10-07T10:32:36.968987Z","iopub.status.idle":"2024-10-07T10:32:48.712674Z","shell.execute_reply.started":"2024-10-07T10:32:36.968937Z","shell.execute_reply":"2024-10-07T10:32:48.711396Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\nimport torch\nfrom accelerate import Accelerator\nimport torch\n\n\n# BitsAndBytes quantization config for 4-bit model loading\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True\n)\n\n\n# Load model and tokenizer with 4-bit quantization\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"asi/gpt-fr-cased-base\",\n    quantization_config=bnb_config,\n    device_map='auto'\n)\n\n# FREEZE WEIGHTS\nfor param in model.parameters():\n    param.requires_grad = False\n\n# LoRa\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.06,\n    bias=\"none\",\n    target_modules=[\"c_attn\", \"c_proj\"],\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, config)","metadata":{"id":"vk31aHTTSRs0","execution":{"iopub.status.busy":"2024-10-07T10:32:48.714259Z","iopub.execute_input":"2024-10-07T10:32:48.714627Z","iopub.status.idle":"2024-10-07T10:32:54.078519Z","shell.execute_reply.started":"2024-10-07T10:32:48.714592Z","shell.execute_reply":"2024-10-07T10:32:54.077459Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\n\nprint_trainable_parameters(model)","metadata":{"id":"B8u0XbIpSRs0","execution":{"iopub.status.busy":"2024-10-07T10:32:54.079771Z","iopub.execute_input":"2024-10-07T10:32:54.080081Z","iopub.status.idle":"2024-10-07T10:32:54.090632Z","shell.execute_reply.started":"2024-10-07T10:32:54.080048Z","shell.execute_reply":"2024-10-07T10:32:54.089626Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"trainable params: 7569408 || all params: 561989120 || trainable%: 1.3468958260259558\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training avec Qlora\ntraining(model)","metadata":{"id":"njZ446_zSRs1","execution":{"iopub.status.busy":"2024-10-07T10:32:54.091825Z","iopub.execute_input":"2024-10-07T10:32:54.092586Z","iopub.status.idle":"2024-10-07T12:05:44.568961Z","shell.execute_reply.started":"2024-10-07T10:32:54.092541Z","shell.execute_reply":"2024-10-07T12:05:44.568041Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiemde-alain\u001b[0m (\u001b[33mdatamation\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113766122192222, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"924ed92c26f342778d4899890ee92eb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/outputs/checkpoint-5350/wandb/run-20241007_103256-442jnrcj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/datamation/huggingface/runs/442jnrcj' target=\"_blank\">output</a></strong> to <a href='https://wandb.ai/datamation/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/datamation/huggingface' target=\"_blank\">https://wandb.ai/datamation/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/datamation/huggingface/runs/442jnrcj' target=\"_blank\">https://wandb.ai/datamation/huggingface/runs/442jnrcj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='800' max='5350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 800/5350 1:32:40 < 8:48:27, 0.14 it/s, Epoch 0/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.627200</td>\n      <td>2.570312</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.614900</td>\n      <td>2.548828</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.588900</td>\n      <td>2.539062</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.588000</td>\n      <td>2.539062</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.587900</td>\n      <td>2.537109</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.597000</td>\n      <td>2.539062</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.574800</td>\n      <td>2.539062</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.575200</td>\n      <td>2.539062</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"id":"mlXYb8UkSRs1"}},{"cell_type":"code","source":"","metadata":{"id":"ZHJpfW0bSRs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# afficher le data\ndata['train'][1]\n","metadata":{"id":"qNmklg9R0ovz","execution":{"iopub.status.busy":"2024-10-07T12:05:44.570423Z","iopub.execute_input":"2024-10-07T12:05:44.571101Z","iopub.status.idle":"2024-10-07T12:05:44.598796Z","shell.execute_reply.started":"2024-10-07T12:05:44.571053Z","shell.execute_reply":"2024-10-07T12:05:44.597920Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'text': 'C\\'est désormais officiel : Alain Juppé n\\'est plus membre des Républicains. L\\'ex-Premier ministre de Jacques Chirac, cofondateur de l\\'UMP en 2002, ne paie plus sa cotisation auprès du parti de droite. Mercredi 9 janvier, le maire de Bordeaux a dénoncé un glissement qui s\\'opère, selon lui, de la droite vers l\\'extême droite. \"Je me reconnais de moins en moins dans cette famille politique, à laquelle je suis pourtant très attaché (...). C\\'est avec tristesse que je l\\'ai quittée, mais il y a une dérive vers des thèses qui sont celles très proches de l\\'extrême droite, et une ambiguïté sur l\\'Europe\", a-t-il déclaré face aux journalistes, réunis pour assister à ses voeux. \"On assiste à cette espèce de transfusion régulière, et sur les thèmes de fond, il y a des moments où je me demande qui j\\'entends à la radio ? Un membre de LR ou du RN ?\", a insisté le maire de Bordeaux. Le même jour, l\\'ex-député Thierry Mariani annonçait son départ de LR pour rallier une liste du Rassemblement national aux européennes de mai prochain. \"Cela fait deux ans que j\\'ai dit que je prenais mes distances avec Les Républicains. Les choses sont acquises depuis bien longtemps\", a tranché Alain Juppé. L\\'ancien candidat à la primaire de la droite pour la présidentielle de 2017 n\\'a jamais fait mystère de son désaccord avec les positions du président des Républicains, Laurent Wauquiez.\\n',\n 'summary': \"Le maire de Bordeaux ne fait plus partie des Républicains et il tient à le montrer. Lors de ses voeux à la presse, l'édile a pris ses distances avec sa famille politique historique, qu'il trouve trop proche de Marine Le Pen.\\n\",\n 'input_ids': [39,\n  11,\n  263,\n  2363,\n  6371,\n  35224,\n  5348,\n  14858,\n  243,\n  11,\n  263,\n  357,\n  2857,\n  262,\n  13951,\n  18,\n  258,\n  11,\n  600,\n  17,\n  23289,\n  1097,\n  214,\n  3446,\n  16210,\n  16,\n  22604,\n  214,\n  210,\n  11,\n  7414,\n  250,\n  4451,\n  16,\n  371,\n  9906,\n  357,\n  398,\n  23295,\n  2481,\n  275,\n  491,\n  214,\n  2526,\n  18,\n  9424,\n  1080,\n  1491,\n  16,\n  239,\n  2420,\n  214,\n  6450,\n  219,\n  7853,\n  249,\n  29061,\n  319,\n  216,\n  11,\n  42440,\n  16,\n  1039,\n  545,\n  16,\n  214,\n  234,\n  2526,\n  995,\n  210,\n  11,\n  15830,\n  522,\n  2526,\n  18,\n  284,\n  2079,\n  501,\n  26203,\n  214,\n  871,\n  250,\n  871,\n  307,\n  503,\n  1329,\n  1222,\n  16,\n  244,\n  2173,\n  421,\n  868,\n  2969,\n  699,\n  12119,\n  46781,\n  269,\n  11,\n  263,\n  383,\n  15637,\n  301,\n  421,\n  210,\n  11,\n  222,\n  42622,\n  16,\n  453,\n  361,\n  528,\n  219,\n  310,\n  17303,\n  995,\n  262,\n  30092,\n  319,\n  426,\n  3050,\n  699,\n  4294,\n  214,\n  210,\n  11,\n  6397,\n  2526,\n  16,\n  246,\n  310,\n  40378,\n  330,\n  210,\n  11,\n  2372,\n  469,\n  219,\n  17,\n  87,\n  17,\n  242,\n  1751,\n  1250,\n  451,\n  4480,\n  16,\n  8942,\n  294,\n  9891,\n  244,\n  496,\n  19359,\n  18,\n  284,\n  3288,\n  16284,\n  244,\n  503,\n  3804,\n  214,\n  3524,\n  2599,\n  9755,\n  16,\n  246,\n  330,\n  260,\n  10284,\n  214,\n  1113,\n  16,\n  361,\n  528,\n  219,\n  262,\n  6551,\n  663,\n  421,\n  501,\n  1640,\n  319,\n  281,\n  11,\n  14006,\n  244,\n  234,\n  4509,\n  490,\n  731,\n  2857,\n  214,\n  15022,\n  450,\n  275,\n  20248,\n  490,\n  469,\n  219,\n  9410,\n  239,\n  2420,\n  214,\n  6450,\n  18,\n  367,\n  610,\n  1126,\n  16,\n  210,\n  11,\n  600,\n  17,\n  48355,\n  7549,\n  7287,\n  3389,\n  20074,\n  375,\n  2359,\n  214,\n  15022,\n  294,\n  19979,\n  310,\n  2765,\n  275,\n  23919,\n  2132,\n  451,\n  5587,\n  214,\n  1371,\n  2706,\n  18,\n  284,\n  15780,\n  482,\n  480,\n  574,\n  301,\n  281,\n  11,\n  222,\n  722,\n  301,\n  421,\n  40134,\n  929,\n  15647,\n  383,\n  449,\n  13951,\n  18,\n  449,\n  2095,\n  426,\n  32481,\n  700,\n  599,\n  2671,\n  469,\n  219,\n  21474,\n  5348,\n  14858,\n  18,\n  258,\n  11,\n  2335,\n  3222,\n  244,\n  234,\n  6546,\n  214,\n  234,\n  2526,\n  294,\n  234,\n  4119,\n  214,\n  2066,\n  243,\n  11,\n  68,\n  1136,\n  482,\n  12634,\n  214,\n  375,\n  14505,\n  383,\n  260,\n  8309,\n  275,\n  979,\n  262,\n  13951,\n  16,\n  4668,\n  22914,\n  18,\n  171,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'labels': [1984,\n  2420,\n  214,\n  6450,\n  371,\n  482,\n  357,\n  1031,\n  262,\n  13951,\n  246,\n  361,\n  3988,\n  244,\n  239,\n  4439,\n  18,\n  2239,\n  214,\n  496,\n  19359,\n  244,\n  234,\n  2157,\n  16,\n  210,\n  11,\n  2786,\n  230,\n  219,\n  1001,\n  496,\n  15647,\n  383,\n  398,\n  1329,\n  1222,\n  4014,\n  16,\n  236,\n  11,\n  242,\n  1883,\n  1368,\n  3159,\n  214,\n  6301,\n  367,\n  4893,\n  18,\n  171,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100]}"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"id":"v4YzS7cA0vi4"}},{"cell_type":"code","source":"data['train'][0]","metadata":{"id":"STQTnj_rCcOT","execution":{"iopub.status.busy":"2024-10-07T12:05:44.599908Z","iopub.execute_input":"2024-10-07T12:05:44.600177Z","iopub.status.idle":"2024-10-07T12:05:44.629917Z","shell.execute_reply.started":"2024-10-07T12:05:44.600145Z","shell.execute_reply":"2024-10-07T12:05:44.629117Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'text': 'Thierry Mariani sur la liste du Rassemblement national (RN, ex-FN) aux européennes ? C\\'est ce qu\\'affirme mardi 11 septembre Chez Pol, la nouvelle newsletter politique de Libération. L\\'ancien député Les Républicain et ministre de Nicolas Sarkozy serait sur le point de rejoindre les troupes de Marine Le Pen pour le élections européennes de 2019. \"Ça va se faire. Ce n\\'est plus qu\\'une question de calendrier. On n\\'est pas obligé de l\\'annoncer tout de suite, à huit mois des européennes\", aurait ainsi assuré un membre influent du RN. Contacté par Franceinfo, M. Mariani n\\'a pas confirmé l\\'information. \"Les élections sont en juin, je ne sais même pas qui sera numéro 1 sur la liste\", a répondu l\\'ancien ministre des Transports. Il reconnaît toutefois, toujours cité par Franceinfo, que son nom sur la liste du RN \"fait partie des possibilités\". \"Fréjus est une ville sympathique mais je n\\'ai pas prévu de m\\'y rendre ce week_end\", a-t-il par ailleurs commenté sur Twitter alors que Marine Le Pen réunit les cadres de son parti ce week-end dans la cité varoise. Une proximité connue avec le FNLa proximité de Thierry Mariani avec le parti frontiste n\\'est pas nouvelle. \"Sans alliés, nous allons rester dans l\\'opposition pour longtemps. Il est temps de renverser la table. Le Front national a évolué. Regardons si un accord ou un rapprochement sont possibles\", avait-il déclaré dans une interview donnée au Journal du Dimanche en mars dernier. Puis, en avril, avait bruissé la rumeur d\\'un rencontre entre l\\'ex-député et Marine Le Pen, qui lui aurait proposé de figurer en position éligible sur la liste de son parti aux européennes. \"Pas de conclusion hâtive\", avait-il à l\\'époque écrit sur Twitter. Le même mois, Thierry Mariani avait cosigné une tribune publiée dans Valeurs actuelles aux côté d\\'élus frontistes appelant à une union des droites.\\n',\n 'summary': \"L'information n'a pas été confirmée par l'intéressé qui déclare toutefois étudier la question.\\n\",\n 'input_ids': [56,\n  6211,\n  1441,\n  7287,\n  3389,\n  330,\n  234,\n  2765,\n  275,\n  23919,\n  2132,\n  339,\n  54,\n  50,\n  16,\n  423,\n  17,\n  27636,\n  13,\n  451,\n  5587,\n  490,\n  269,\n  11,\n  263,\n  376,\n  236,\n  11,\n  24628,\n  1715,\n  1358,\n  1556,\n  7561,\n  7256,\n  16,\n  234,\n  1228,\n  17388,\n  2151,\n  372,\n  1222,\n  214,\n  9656,\n  18,\n  258,\n  11,\n  2335,\n  3494,\n  449,\n  44013,\n  246,\n  1097,\n  214,\n  3008,\n  4179,\n  1507,\n  330,\n  239,\n  1284,\n  214,\n  4926,\n  260,\n  4438,\n  214,\n  6301,\n  367,\n  4893,\n  294,\n  239,\n  2856,\n  5587,\n  214,\n  2494,\n  18,\n  284,\n  15015,\n  857,\n  323,\n  608,\n  18,\n  732,\n  243,\n  11,\n  263,\n  357,\n  236,\n  11,\n  408,\n  1700,\n  214,\n  7200,\n  18,\n  666,\n  243,\n  11,\n  263,\n  322,\n  9569,\n  214,\n  210,\n  11,\n  16644,\n  509,\n  214,\n  1402,\n  16,\n  244,\n  2961,\n  959,\n  262,\n  5587,\n  469,\n  1568,\n  880,\n  4131,\n  249,\n  2857,\n  29464,\n  275,\n  20248,\n  18,\n  31780,\n  280,\n  763,\n  21137,\n  16,\n  290,\n  18,\n  7287,\n  3389,\n  243,\n  11,\n  68,\n  322,\n  4614,\n  210,\n  11,\n  3990,\n  18,\n  284,\n  2874,\n  2856,\n  426,\n  250,\n  1471,\n  16,\n  421,\n  371,\n  1268,\n  610,\n  322,\n  319,\n  924,\n  3286,\n  304,\n  330,\n  234,\n  2765,\n  469,\n  219,\n  5674,\n  210,\n  11,\n  2335,\n  1097,\n  262,\n  12839,\n  18,\n  389,\n  6735,\n  2530,\n  16,\n  953,\n  4517,\n  280,\n  763,\n  21137,\n  16,\n  301,\n  375,\n  579,\n  330,\n  234,\n  2765,\n  275,\n  20248,\n  284,\n  3074,\n  1031,\n  262,\n  12474,\n  617,\n  284,\n  42,\n  410,\n  5891,\n  314,\n  310,\n  1124,\n  19714,\n  453,\n  421,\n  243,\n  11,\n  222,\n  322,\n  3577,\n  214,\n  226,\n  11,\n  92,\n  2535,\n  376,\n  3410,\n  67,\n  352,\n  469,\n  219,\n  17,\n  87,\n  17,\n  242,\n  280,\n  2321,\n  9035,\n  330,\n  5030,\n  809,\n  301,\n  6301,\n  367,\n  4893,\n  11570,\n  260,\n  9334,\n  214,\n  375,\n  491,\n  376,\n  3410,\n  17,\n  352,\n  307,\n  234,\n  4517,\n  15764,\n  2392,\n  18,\n  856,\n  4987,\n  5626,\n  383,\n  239,\n  7567,\n  2285,\n  4987,\n  214,\n  7549,\n  7287,\n  3389,\n  383,\n  239,\n  491,\n  46001,\n  243,\n  11,\n  263,\n  322,\n  1228,\n  18,\n  284,\n  28722,\n  8985,\n  16,\n  546,\n  5019,\n  2808,\n  307,\n  210,\n  11,\n  3675,\n  294,\n  2671,\n  18,\n  389,\n  314,\n  837,\n  214,\n  17611,\n  234,\n  2276,\n  18,\n  367,\n  6945,\n  2132,\n  219,\n  12435,\n  18,\n  43802,\n  365,\n  467,\n  249,\n  2014,\n  450,\n  249,\n  13612,\n  426,\n  8285,\n  469,\n  588,\n  17,\n  242,\n  1751,\n  307,\n  310,\n  7809,\n  7889,\n  272,\n  7577,\n  275,\n  6658,\n  250,\n  1493,\n  961,\n  18,\n  3409,\n  16,\n  250,\n  1754,\n  16,\n  588,\n  933,\n  12908,\n  208,\n  234,\n  16244,\n  207,\n  11,\n  232,\n  2053,\n  553,\n  210,\n  11,\n  600,\n  17,\n  48355,\n  246,\n  6301,\n  367,\n  4893,\n  16,\n  319,\n  545,\n  1568,\n  5811,\n  214,\n  20821,\n  250,\n  2522,\n  45865,\n  330,\n  234,\n  2765,\n  214,\n  375,\n  491,\n  451,\n  5587,\n  18,\n  284,\n  12484,\n  214,\n  10545,\n  20145,\n  1671,\n  469,\n  588,\n  17,\n  242,\n  244,\n  210,\n  11,\n  2876,\n  2188,\n  330,\n  5030,\n  18,\n  367,\n  610,\n  959,\n  16,\n  7549,\n  7287,\n  3389,\n  588,\n  42637,\n  11407,\n  310,\n  10742,\n  6249,\n  307,\n  21694,\n  360,\n  13950,\n  451,\n  1426,\n  207,\n  11,\n  19652,\n  3405,\n  7008,\n  15557,\n  244,\n  310,\n  12846,\n  262,\n  35394,\n  18,\n  171,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'labels': [48,\n  11,\n  3990,\n  243,\n  11,\n  68,\n  322,\n  433,\n  13989,\n  280,\n  210,\n  11,\n  21672,\n  319,\n  6212,\n  2530,\n  10788,\n  234,\n  1700,\n  18,\n  171,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100]}"},"metadata":{}}]}]}